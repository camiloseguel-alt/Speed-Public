{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camiloseguel-alt/Speed-Public/blob/main/RT_MS_V.1.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar los paquetes necesarios\n",
        "%pip install --quiet google-cloud-bigquery\n",
        "!pip install --quiet google-cloud-bigquery pandas openpyxl\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.colab import auth\n",
        "\n",
        "# Importar las librerías necesarias\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Authenticate to Google Cloud\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Conectar al cliente de BigQuery\n",
        "# Construct a BigQuery client object.\n",
        "# TODO(developer): Set default project.\n",
        "# client = bigquery.Client(project=\"your-project-id\")\n",
        "client = bigquery.Client(project=\"meli-bi-data\")\n",
        "\n",
        "\n",
        "# Obtener información de la tabla\n",
        "table_ref = client.dataset(\"WHOWNER\", project=\"meli-bi-data\").table(\"LK_SHP_SHIPMENTS_HISTORICAL_ND\")\n",
        "table = client.get_table(table_ref)\n",
        "\n",
        "# Función para mostrar el menú de selección para información histórica/real\n",
        "def menu_selection_historical():\n",
        "    while True:\n",
        "        print(\"\\n**********************************************************************\")\n",
        "        print(\"POR FAVOR, PROPORCIONE LOS SIGUIENTES PARÁMETROS PARA OBTENER LA INFORMACIÓN HISTORICA/REAL:\")\n",
        "        print(\"**********************************************************************\")\n",
        "        print(\"\\nSELECCIONE EL PAÍS (SIT_SITE_ID):\")\n",
        "        site_options = ['MCO', 'MLC', 'MLA', 'MPE', 'MLU', 'MLM', 'MLB', 'MEC']\n",
        "        site_options.sort() # Sort the list alphabetically\n",
        "        for idx, option in enumerate(site_options):\n",
        "            print(f\"{idx + 1}. {option}\")\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                country_index = int(input(\"Ingrese el número del país: \")) - 1\n",
        "                if 0 <= country_index < len(site_options):\n",
        "                    country = site_options[country_index]\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"Número de país inválido. Inténtalo de nuevo.\")\n",
        "            except ValueError:\n",
        "                print(\"Entrada inválida. Por favor, ingrese un número.\")\n",
        "\n",
        "\n",
        "        print(\"\\nSELEccione EL TIPO DE INFORMACIÓN:\")\n",
        "        info_types = ['First Visit', 'Handling', 'Created']\n",
        "        for idx, option in enumerate(info_types):\n",
        "            print(f\"{idx + 1}. {option}\")\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                info_type_index = int(input(\"Ingrese el número del tipo de información: \")) - 1\n",
        "                if 0 <= info_type_index < len(info_types):\n",
        "                    info_type = info_types[info_type_index]\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"Número de tipo de información inválido. Inténtalo de nuevo.\")\n",
        "            except ValueError:\n",
        "                print(\"Entrada inválida. Por favor, ingrese un número.\")\n",
        "\n",
        "        # Año\n",
        "        while True:\n",
        "            try:\n",
        "                year = int(input(f\"\\nINGRESE EL AÑO (2023 - {datetime.now().year}): \"))\n",
        "                if 2023 <= year <= datetime.now().year:\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"Fecha inválida, debe ser entre 2023 y el año actual. Inténtalo de nuevo.\")\n",
        "            except ValueError:\n",
        "                print(\"Entrada inválida. Por favor, ingrese un número.\")\n",
        "\n",
        "\n",
        "        # Mes\n",
        "        while True:\n",
        "            try:\n",
        "                month = int(input(f\"\\nINGRESE EL MES (1 - 12): \"))\n",
        "                if 1 <= month <= 12:\n",
        "                    if year == datetime.now().year and month > datetime.now().month:\n",
        "                         print(\"Mes inválido para el año actual. Inténtalo de nuevo.\")\n",
        "                    else:\n",
        "                        break\n",
        "                else:\n",
        "                    print(\"Mes inválido, debe ser entre 1 y 12. Inténtalo de nuevo.\")\n",
        "            except ValueError:\n",
        "                print(\"Entrada inválida. Por favor, ingrese un número.\")\n",
        "\n",
        "\n",
        "        return country, info_type, year, month\n",
        "\n",
        "# Función para generar y ejecutar la consulta para información histórica/real\n",
        "def execute_query_historical(country, info_type, year, month):\n",
        "    month_str = f\"{month:02}\"\n",
        "\n",
        "    date_column_map = {\n",
        "        'First Visit': 'SHP_DATE_FIRST_VISIT_ID_LTZ',\n",
        "        'Handling': 'SHP_DATE_HANDLING_ID_LTZ',\n",
        "        'Created': 'SHP_DATE_CREATED_ID'\n",
        "    }\n",
        "\n",
        "    date_column = date_column_map[info_type]\n",
        "\n",
        "    print(f\"\\nExecuting query for Historical/Real Info with:\")\n",
        "    print(f\"  Country: {country}\")\n",
        "    print(f\"  Info Type: {info_type}\")\n",
        "    print(f\"  Date Column: {date_column}\")\n",
        "    print(f\"  Year: {year}\")\n",
        "    print(f\"  Month: {month}\")\n",
        "\n",
        "\n",
        "    query = f\"\"\"\n",
        "    SELECT\n",
        "        SIT_SITE_ID,\n",
        "        COUNT(SHP_SHIPMENT_ID) AS SHP,\n",
        "        SUM (SHP_QUANTITY) AS SIS,\n",
        "        CASE\n",
        "            WHEN SIT_SITE_ID = 'MCO' AND SHP_ADD_STATE_ID_BUYER = 'CO-DC' THEN 'CO-BDC'\n",
        "            ELSE SHP_ADD_STATE_ID_BUYER\n",
        "        END AS SHP_ADD_STATE_ID_BUYER,\n",
        "        CASE\n",
        "            WHEN SIT_SITE_ID = 'MCO' AND SHP_ADD_STATE_ID_SELLER = 'CO-DC' THEN 'CO-BDC'\n",
        "            ELSE SHP_ADD_STATE_ID_SELLER\n",
        "        END AS SHP_ADD_STATE_ID_SELLER,\n",
        "        EXTRACT(YEAR FROM {date_column}) AS YEAR,\n",
        "        EXTRACT(MONTH FROM {date_column}) AS MONTH,\n",
        "        CASE\n",
        "            WHEN SHP_PICKING_TYPE_ID = 'drop_off' THEN 'DS'\n",
        "            WHEN SHP_PICKING_TYPE_ID = 'xd_drop_off' THEN 'XD'\n",
        "            WHEN SHP_PICKING_TYPE_ID = 'fulfillment' THEN 'FUL'\n",
        "            WHEN SHP_PICKING_TYPE_ID = 'cross_docking' THEN 'XD'\n",
        "            WHEN SHP_PICKING_TYPE_ID = 'self_service' THEN 'FLEX'\n",
        "            ELSE NULL\n",
        "        END AS SHP_PICKING_TYPE_ID,\n",
        "        CASE\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 0 THEN 'SD'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 1 THEN 'ND'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 2 THEN '2D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 3 THEN '3D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 4 THEN '4D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 5 THEN '5D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 6 THEN '6D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 7 THEN '7D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 8 THEN '8D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 9 THEN '9D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS > 9 THEN '9DP'\n",
        "            ELSE NULL\n",
        "        END AS SHP_LEAD_TIME_NATURAL_DAYS\n",
        "    FROM `meli-bi-data.WHOWNER.LK_SHP_SHIPMENTS_HISTORICAL_ND`\n",
        "    WHERE\n",
        "        SIT_SITE_ID = '{country}' AND\n",
        "        LOWER(SHP_FLOW_TYPE) = 'forward' AND\n",
        "        SHP_SOURCE_ID = 'MELI' AND\n",
        "        EXTRACT(YEAR FROM {date_column}) = {year} AND\n",
        "        EXTRACT(MONTH FROM {date_column}) = {month} AND\n",
        "        SHP_LEAD_TIME_NATURAL_DAYS IS NOT NULL\n",
        "    GROUP BY\n",
        "        SIT_SITE_ID,\n",
        "        SHP_ADD_STATE_ID_BUYER,\n",
        "        SHP_ADD_STATE_ID_SELLER,\n",
        "        YEAR,\n",
        "        MONTH,\n",
        "        SHP_PICKING_TYPE_ID,\n",
        "        SHP_LEAD_TIME_NATURAL_DAYS\n",
        "    \"\"\"\n",
        "\n",
        "    df = client.query(query).result().to_dataframe()\n",
        "\n",
        "    print(f\"Number of rows returned by the query: {len(df)}\")\n",
        "    print(f\"Data type of 'SIS' column: {df['SIS'].dtype}\")\n",
        "    # print(\"\\nDataFrame columns after fetching from BigQuery:\")\n",
        "    # print(df.columns)\n",
        "    # Remove the display of the first 5 rows after fetching from BigQuery\n",
        "    # display(df.head())\n",
        "\n",
        "\n",
        "    # Rename Year and Month columns based on info_type\n",
        "    rename_map = {}\n",
        "    if info_type == 'First Visit':\n",
        "        rename_map['YEAR'] = 'YEAR_FV'\n",
        "        rename_map['MONTH'] = 'MONTH_FV'\n",
        "        year_col = 'YEAR_FV'\n",
        "        month_col = 'MONTH_FV'\n",
        "    elif info_type == 'Handling':\n",
        "        rename_map['YEAR'] = 'YEAR_HT'\n",
        "        rename_map['MONTH'] = 'MONTH_HT'\n",
        "        year_col = 'YEAR_HT'\n",
        "        month_col = 'MONTH_HT'\n",
        "    elif info_type == 'Created':\n",
        "        rename_map['YEAR'] = 'YEAR_C'\n",
        "        rename_map['MONTH'] = 'MONTH_C'\n",
        "        year_col = 'YEAR_C'\n",
        "        month_col = 'MONTH_C'\n",
        "\n",
        "\n",
        "    df.rename(columns=rename_map, inplace=True)\n",
        "\n",
        "    # Explicitly convert 'SIS' to numeric, coercing errors will turn unparseable values into NaN\n",
        "    df['SIS'] = pd.to_numeric(df['SIS'], errors='coerce')\n",
        "\n",
        "\n",
        "    df = df[df['SHP_PICKING_TYPE_ID'].notnull()]  # Ignorar no estándar\n",
        "\n",
        "    # Print unique values in SHP_LEAD_TIME_NATURAL_DAYS before standardization to debug\n",
        "    # print(\"Unique values in SHP_LEAD_TIME_NATURAL_DAYS before standardization:\")\n",
        "    # The SHP_LEAD_TIME_NATURAL_DAYS column is now the result of the CASE statement\n",
        "    # print(df['SHP_LEAD_TIME_NATURAL_DAYS'].unique())\n",
        "\n",
        "\n",
        "    # Calculate column SHARE_PT (J) based on the provided formula\n",
        "    # SUMIFS($H:$H;$A:$A;$A2;$B:$B;$B2;$C:$C;$C2;$D:$D;$D2;$E:$E;$E2;$F:$F;$F2;$G:$G;$G2)/SUMIFS($H:$H;$A:$A;$A2;$B:$B;$B2;$C:$C;$C2)\n",
        "    # H -> SHP, A -> SIT_SITE_ID, B -> YEAR_FV/HT/C, C -> MONTH_FV/HT/C, D -> SHP_PICKING_TYPE_ID, E -> SHP_ADD_STATE_ID_BUYER, F -> SHP_ADD_STATE_ID_SELLER, G -> SHP_LEAD_TIME_NATURAL_DAYS\n",
        "\n",
        "    # Calculate the denominator first (sum of SHP for each SIT_SITE_ID, Year, Month group)\n",
        "    denominator = df.groupby(['SIT_SITE_ID', year_col, month_col])['SHP'].transform('sum')\n",
        "\n",
        "    # Calculate the numerator (sum of SHP for each group defined by all relevant columns)\n",
        "    numerator = df.groupby(['SIT_SITE_ID', year_col, month_col, 'SHP_PICKING_TYPE_ID', 'SHP_ADD_STATE_ID_BUYER', 'SHP_ADD_STATE_ID_SELLER', 'SHP_LEAD_TIME_NATURAL_DAYS'])['SHP'].transform('sum')\n",
        "\n",
        "    # Calculate SHARE_PT, handling division by zero\n",
        "    df['SHARE_PT'] = numerator / denominator\n",
        "    df['SHARE_PT'] = df['SHARE_PT'].fillna(0) # Replace NaN resulting from division by zero with 0\n",
        "\n",
        "\n",
        "    # Calculate column SPEED_PT (K) based on the provided formula\n",
        "    # H2/SUMIFS($H:$H;$A:$A;$A2;$B:$B;$B2;$C:$C;$C2;$D:$D;D2)\n",
        "    # H -> SHP, A -> SIT_SITE_ID, B -> YEAR_FV/HT/C, C -> MONTH_FV/HT/C, D -> SHP_PICKING_TYPE_ID\n",
        "    speed_pt_denominator = df.groupby(['SIT_SITE_ID', year_col, month_col, 'SHP_PICKING_TYPE_ID'])['SHP'].transform('sum')\n",
        "    df['SPEED_PT'] = df['SHP'] / speed_pt_denominator\n",
        "    df['SPEED_PT'] = df['SPEED_PT'].fillna(0) # Replace NaN resulting from division by zero with 0\n",
        "\n",
        "\n",
        "    # Calculate column SPEED_ALL_NET (L) based on the provided formula\n",
        "    # K2*SUMIFS($J:$J;$A:$A;$A2;$B:$B;$B2;$C:$C;$C2;$D:$D;$D2)\n",
        "    # J -> SHARE_PT, A -> SIT_SITE_ID, B -> YEAR_FV/HT/C, C -> MONTH_FV/HT/C, D -> SHP_PICKING_TYPE_ID\n",
        "    speed_all_net_sumifs = df.groupby(['SIT_SITE_ID', year_col, month_col, 'SHP_PICKING_TYPE_ID'])['SHARE_PT'].transform('sum')\n",
        "    df['SPEED_ALL_NET'] = df['SPEED_PT'] * speed_all_net_sumifs\n",
        "\n",
        "\n",
        "    # print(\"\\nDataFrame columns after calculating new columns:\")\n",
        "    # print(df.columns)\n",
        "    # Remove the display of the first 5 rows after calculating new columns\n",
        "    # display(df.head())\n",
        "\n",
        "\n",
        "    # Reorder columns\n",
        "    if info_type == 'First Visit':\n",
        "        ordered_columns = ['SIT_SITE_ID', 'YEAR_FV', 'MONTH_FV', 'SHP_PICKING_TYPE_ID', 'SHP_ADD_STATE_ID_BUYER', 'SHP_ADD_STATE_ID_SELLER', 'SHP_LEAD_TIME_NATURAL_DAYS', 'SHP', 'SIS', 'SHARE_PT', 'SPEED_PT', 'SPEED_ALL_NET']\n",
        "    elif info_type == 'Handling':\n",
        "         ordered_columns = ['SIT_SITE_ID', 'YEAR_HT', 'MONTH_HT', 'SHP_PICKING_TYPE_ID', 'SHP_ADD_STATE_ID_BUYER', 'SHP_ADD_STATE_ID_SELLER', 'SHP_LEAD_TIME_NATURAL_DAYS', 'SHP', 'SIS', 'SHARE_PT', 'SPEED_PT', 'SPEED_ALL_NET']\n",
        "    elif info_type == 'Created':\n",
        "        ordered_columns = ['SIT_SITE_ID', 'YEAR_C', 'MONTH_C', 'SHP_PICKING_TYPE_ID', 'SHP_ADD_STATE_ID_BUYER', 'SHP_ADD_STATE_ID_SELLER', 'SHP_LEAD_TIME_NATURAL_DAYS', 'SHP', 'SIS', 'SHARE_PT', 'SPEED_PT', 'SPEED_ALL_NET']\n",
        "\n",
        "    # Ensure all required columns exist in the DataFrame before reordering\n",
        "    missing_columns = [col for col in ordered_columns if col not in df.columns]\n",
        "    if missing_columns:\n",
        "        print(f\"Warning: The following columns are missing from the DataFrame and cannot be reordered: {missing_columns}\")\n",
        "        # Proceed with reordering only the existing columns\n",
        "        ordered_columns = [col for col in ordered_columns if col in df.columns]\n",
        "\n",
        "\n",
        "    df = df[ordered_columns]\n",
        "\n",
        "    return df\n",
        "\n",
        "# Función para mostrar el menú de selección para información del plan\n",
        "def menu_selection_plan():\n",
        "    while True:\n",
        "        print(\"\\n**********************************************************************\")\n",
        "        print(\"POR FAVOR, PROPORCIONE LOS SIGUIENTES PARÁMETROS PARA OBTENER LA INFORMACIÓN DEL PLAN:\")\n",
        "        print(\"**********************************************************************\")\n",
        "\n",
        "        # Prompt for SPIDER_ID first\n",
        "        while True:\n",
        "            try:\n",
        "                spider_id = int(input(\"\\nINGRESE EL ID DEL PLAN (CAMPO SPIDER_ID): \"))\n",
        "                break\n",
        "            except ValueError:\n",
        "                print(\"Entrada inválida. Por favor, ingrese un número entero para el SPIDER_ID.\")\n",
        "\n",
        "        # Get unique sites for the entered spider_id\n",
        "        sites_query = f\"SELECT DISTINCT SITE FROM `meli-bi-data.SBOX_NETWORKD.SPIDER_HISTORY` WHERE SPIDER_ID = {spider_id} ORDER BY SITE\"\n",
        "        sites_df = client.query(sites_query).result().to_dataframe()\n",
        "        site_options = sites_df['SITE'].tolist()\n",
        "\n",
        "        if not site_options:\n",
        "            print(f\"No se encontraron países para el SPIDER_ID: {spider_id}. Por favor, intente con un SPIDER_ID diferente.\")\n",
        "            continue # Restart the loop to ask for SPIDER_ID again\n",
        "        elif len(site_options) > 1:\n",
        "            print(f\"Warning: Multiple countries found for SPIDER_ID {spider_id}. Please select one.\")\n",
        "            # Display the options and let the user select\n",
        "            print(\"\\nSELECCIONE EL PAÍS (SITE):\")\n",
        "            for idx, option in enumerate(site_options):\n",
        "                print(f\"{idx + 1}. {option}\")\n",
        "            while True:\n",
        "                try:\n",
        "                    country_index = int(input(\"Ingrese el número del país: \")) - 1\n",
        "                    if 0 <= country_index < len(site_options):\n",
        "                        country = site_options[country_index]\n",
        "                        break\n",
        "                    else:\n",
        "                        print(\"Número de país inválido. Inténtalo de nuevo.\")\n",
        "                except ValueError:\n",
        "                    print(\"Entrada inválida. Por favor, ingrese un número.\")\n",
        "        else:\n",
        "            # Only one country found, ask for confirmation with the new text\n",
        "            country = site_options[0]\n",
        "            while True:\n",
        "                confirm = input(f\"El ID seleccionado corresponde a {country} es ¿correcto? (si/no): \").lower()\n",
        "                if confirm == 'si':\n",
        "                    break # Exit the confirmation loop\n",
        "                elif confirm == 'no':\n",
        "                    print(\"Por favor, ingrese el ID del plan nuevamente.\")\n",
        "                    break # Exit the confirmation loop to re-enter spider_id\n",
        "                else:\n",
        "                    print(\"Respuesta inválida. Por favor, ingrese 'si' o 'no'.\")\n",
        "\n",
        "            if confirm == 'no':\n",
        "                continue # Restart the outer loop to ask for SPIDER_ID again\n",
        "\n",
        "\n",
        "        # Get available years and months for the selected spider_id and country\n",
        "        year_month_query = f\"\"\"\n",
        "        SELECT DISTINCT YEAR_NUMBER, MONTH_NUMBER\n",
        "        FROM `meli-bi-data.SBOX_NETWORKD.SPIDER_HISTORY`\n",
        "        WHERE SITE = '{country}'\n",
        "          AND SPIDER_ID = {spider_id}\n",
        "        ORDER BY YEAR_NUMBER, MONTH_NUMBER\n",
        "        \"\"\"\n",
        "        year_month_df = client.query(year_month_query).result().to_dataframe()\n",
        "\n",
        "        if year_month_df.empty:\n",
        "             print(f\"No se encontraron datos de año/mes para el país: {country} y SPIDER_ID: {spider_id}. Por favor, intente con un SPIDER_ID o país diferente.\")\n",
        "             continue # Restart the loop\n",
        "\n",
        "        print(f\"\\nAños y Meses disponibles para el país: {country} y SPIDER_ID: {spider_id}:\")\n",
        "        for index, row in year_month_df.iterrows():\n",
        "            # Convert to int before printing to remove decimal\n",
        "            print(f\"  - Año: {int(row['YEAR_NUMBER'])}, Mes: {int(row['MONTH_NUMBER'])}\")\n",
        "\n",
        "\n",
        "        # Año\n",
        "        while True:\n",
        "            try:\n",
        "                year = int(input(f\"\\nINGRESE EL AÑO: \"))\n",
        "                # Check if the entered year is in the available years for the selected spider_id and country\n",
        "                if year in year_month_df['YEAR_NUMBER'].unique():\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"Año inválido. Por favor, ingrese un año de la lista disponible.\")\n",
        "            except ValueError:\n",
        "                print(\"Entrada inválida. Por favor, ingrese un número.\")\n",
        "\n",
        "\n",
        "        # Mes\n",
        "        while True:\n",
        "            try:\n",
        "                month = int(input(f\"\\nINGRESE EL MES: \"))\n",
        "                # Check if the entered month is in the available months for the selected year, spider_id, and country\n",
        "                if month in year_month_df[year_month_df['YEAR_NUMBER'] == year]['MONTH_NUMBER'].unique():\n",
        "                    break\n",
        "                else:\n",
        "                    print(f\"Mes inválido para el año {year}. Por favor, ingrese un mes de la lista disponible para este año.\")\n",
        "            except ValueError:\n",
        "                print(\"Entrada inválida. Por favor, ingrese un número.\")\n",
        "\n",
        "\n",
        "        return country, spider_id, year, month\n",
        "\n",
        "# Función para generar y ejecutar la consulta para información del plan\n",
        "def execute_query_plan(country, spider_id, year, month):\n",
        "    print(f\"\\nExecuting query for Plan Info with:\")\n",
        "    print(f\"  Country: {country}\")\n",
        "    print(f\"  Spider ID: {spider_id}\")\n",
        "    print(f\"  Year: {year}\")\n",
        "    print(f\"  Month: {month}\")\n",
        "\n",
        "    query = f\"\"\"\n",
        "    SELECT\n",
        "        SPIDER_ID,\n",
        "        SITE,\n",
        "        YEAR_NUMBER,\n",
        "        MONTH_NUMBER,\n",
        "        PICKING_TYPE,\n",
        "        CASE\n",
        "            WHEN SITE = 'MCO' AND BUYER_STATE = 'CO-DC' THEN 'CO-BDC'\n",
        "            ELSE BUYER_STATE\n",
        "        END AS BUYER_STATE,\n",
        "        CASE\n",
        "            WHEN SITE = 'MCO' AND SELLER_STATE = 'CO-DC' THEN 'CO-BDC'\n",
        "            ELSE SELLER_STATE\n",
        "        END AS SELLER_STATE,\n",
        "        SUM(SHIPMENTS) AS SHP,\n",
        "        SUM(SIS) AS SIS\n",
        "    FROM `meli-bi-data.SBOX_NETWORKD.SPIDER_HISTORY`\n",
        "    WHERE\n",
        "        SITE = '{country}' AND\n",
        "        SPIDER_ID = {spider_id} AND\n",
        "        YEAR_NUMBER = {year} AND\n",
        "        MONTH_NUMBER = {month} AND\n",
        "        LOWER(FLOW_TYPE) = 'forward'\n",
        "    GROUP BY\n",
        "        SPIDER_ID,\n",
        "        SITE,\n",
        "        YEAR_NUMBER,\n",
        "        MONTH_NUMBER,\n",
        "        PICKING_TYPE,\n",
        "        BUYER_STATE,\n",
        "        SELLER_STATE\n",
        "    \"\"\"\n",
        "\n",
        "    df = client.query(query).result().to_dataframe()\n",
        "\n",
        "    print(f\"Number of rows returned by the plan query: {len(df)}\")\n",
        "    # print(\"\\nDataFrame columns after fetching from BigQuery (Plan):\")\n",
        "    # print(df.columns)\n",
        "    # Remove the display of the first 5 rows after fetching from BigQuery\n",
        "    # display(df.head())\n",
        "\n",
        "    # Perform calculations for SHARE_PT, SPEED_PT, and SPEED_ALL_NET\n",
        "    # Ensure 'SHP' is numeric\n",
        "    df['SHP'] = pd.to_numeric(df['SHP'], errors='coerce')\n",
        "    df = df.dropna(subset=['SHP']) # Drop rows where SHP could not be converted\n",
        "\n",
        "    # Calculate the denominator for SHARE_PT (sum of SHP for each Site, Year, Month group)\n",
        "    # Assuming the relevant grouping columns are SITE, YEAR_NUMBER, MONTH_NUMBER\n",
        "    denominator_share_pt = df.groupby(['SITE', 'YEAR_NUMBER', 'MONTH_NUMBER'])['SHP'].transform('sum')\n",
        "\n",
        "    # Calculate the numerator for SHARE_PT (sum of SHP for each group defined by all relevant columns)\n",
        "    # Assuming the relevant grouping columns are SITE, YEAR_NUMBER, MONTH_NUMBER, PICKING_TYPE, BUYER_STATE, SELLER_STATE\n",
        "    numerator_share_pt = df.groupby(['SITE', 'YEAR_NUMBER', 'MONTH_NUMBER', 'PICKING_TYPE', 'BUYER_STATE', 'SELLER_STATE'])['SHP'].transform('sum')\n",
        "\n",
        "    # Calculate SHARE_PT, handling division by zero\n",
        "    df['SHARE_PT'] = numerator_share_pt / denominator_share_pt\n",
        "    df['SHARE_PT'] = df['SHARE_PT'].fillna(0) # Replace NaN resulting from division by zero with 0\n",
        "\n",
        "\n",
        "    # Calculate column SPEED_PT based on the provided formula\n",
        "    # H2/SUMIFS($H:$H;$A:$A;$A2;$B:$B;$B2;$C:$C;$C2;$D:$D;D2)\n",
        "    # H -> SHP, A -> SITE, B -> YEAR_NUMBER, C -> MONTH_NUMBER, D -> PICKING_TYPE\n",
        "    speed_pt_denominator = df.groupby(['SITE', 'YEAR_NUMBER', 'MONTH_NUMBER', 'PICKING_TYPE'])['SHP'].transform('sum')\n",
        "    df['SPEED_PT'] = df['SHP'] / speed_pt_denominator\n",
        "    df['SPEED_PT'] = df['SPEED_PT'].fillna(0) # Replace NaN resulting from division by zero with 0\n",
        "\n",
        "\n",
        "    # Calculate column SPEED_ALL_NET based on the provided formula\n",
        "    # K2*SUMIFS($J:$J;$A:$A;$A2;$B:$B;$B2;$C:$C;$C2;$D:$D;$D2)\n",
        "    # J -> SHARE_PT, A -> SITE, B -> YEAR_NUMBER, C -> MONTH_NUMBER, D -> SHP_PICKING_TYPE_ID\n",
        "    speed_all_net_sumifs = df.groupby(['SITE', 'YEAR_NUMBER', 'MONTH_NUMBER', 'PICKING_TYPE'])['SHARE_PT'].transform('sum')\n",
        "    df['SPEED_ALL_NET'] = df['SPEED_PT'] * speed_all_net_sumifs\n",
        "\n",
        "    # Convert YEAR_NUMBER, MONTH_NUMBER, SHP, and SIS to integers\n",
        "    df['YEAR_NUMBER'] = df['YEAR_NUMBER'].astype(int)\n",
        "    df['MONTH_NUMBER'] = df['MONTH_NUMBER'].astype(int)\n",
        "    df['SHP'] = df['SHP'].astype(int)\n",
        "    df['SIS'] = df['SIS'].astype(int)\n",
        "\n",
        "\n",
        "    # Reorder columns for the plan data\n",
        "    ordered_columns_plan = ['SPIDER_ID', 'SITE', 'YEAR_NUMBER', 'MONTH_NUMBER', 'PICKING_TYPE', 'BUYER_STATE', 'SELLER_STATE', 'SHP', 'SIS', 'SHARE_PT', 'SPEED_PT', 'SPEED_ALL_NET']\n",
        "\n",
        "    # Ensure all required columns exist in the DataFrame before reordering\n",
        "    missing_columns_plan = [col for col in ordered_columns_plan if col not in df.columns]\n",
        "    if missing_columns_plan:\n",
        "        print(f\"Warning: The following columns are missing from the Plan DataFrame and cannot be reordered: {missing_columns_plan}\")\n",
        "        # Proceed with reordering only the existing columns\n",
        "        ordered_columns_plan = [col for col in ordered_columns_plan if col in df.columns]\n",
        "\n",
        "    df = df[ordered_columns_plan]\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Ejecutar los menús y las consultas, y guardar en diferentes hojas\n",
        "country_hist, info_type, year_hist, month_hist = menu_selection_historical()\n",
        "df_historical = execute_query_historical(country_hist, info_type, year_hist, month_hist)\n",
        "\n",
        "# Modified to prompt for SPIDER_ID first and then use it for subsequent filters\n",
        "country_plan, spider_id_plan, year_plan, month_plan = menu_selection_plan()\n",
        "\n",
        "# Check if df_plan was successfully created before attempting to save\n",
        "df_plan = execute_query_plan(country_plan, spider_id_plan, year_plan, month_plan)\n",
        "\n",
        "\n",
        "# Guardar resultados a un archivo Excel con múltiples hojas\n",
        "with pd.ExcelWriter(\"info.xlsx\") as writer:\n",
        "    df_historical.to_excel(writer, sheet_name=\"Info Real\", index=False)\n",
        "    # Only attempt to save df_plan if it exists and is not empty\n",
        "    if df_plan is not None and not df_plan.empty:\n",
        "        df_plan.to_excel(writer, sheet_name=\"Info Plan\", index=False)\n",
        "        print(\"\\nResultados guardados en 'info.xlsx' con las hojas 'Info Real' e 'Info Plan'.\")\n",
        "    else:\n",
        "        print(\"\\nCould not retrieve plan information or plan data is empty. 'Info Plan' sheet not added to Excel file.\")"
      ],
      "metadata": {
        "id": "T6hElmEko7FI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}