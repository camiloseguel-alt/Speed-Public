{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camiloseguel-alt/Speed-Public/blob/main/Share_PT_%26_Geo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar los paquetes necesarios\n",
        "%pip install --quiet google-cloud-bigquery\n",
        "!pip install --quiet google-cloud-bigquery pandas openpyxl\n",
        "\n",
        "from google.cloud import bigquery\n",
        "from google.colab import auth\n",
        "\n",
        "# Importar las librerías necesarias\n",
        "from google.cloud import bigquery\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Authenticate to Google Cloud\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Conectar al cliente de BigQuery\n",
        "# Construct a BigQuery client object.\n",
        "# TODO(developer): Set default project.\n",
        "# client = bigquery.Client(project=\"your-project-id\")\n",
        "client = bigquery.Client(project=\"meli-bi-data\")\n",
        "\n",
        "\n",
        "# Obtener información de la tabla\n",
        "table_ref = client.dataset(\"WHOWNER\", project=\"meli-bi-data\").table(\"LK_SHP_SHIPMENTS_HISTORICAL_ND\")\n",
        "table = client.get_table(table_ref)\n",
        "\n",
        "# Función para mostrar el menú de selección\n",
        "def menu_selection():\n",
        "    while True:\n",
        "        print(\"\\n**********************************************************************\")\n",
        "        print(\"POR FAVOR, PROPORCIONE LOS SIGUIENTES PARÁMETROS PARA OBTENER LA INFORMACIÓN HISTORICA/REAL:\")\n",
        "        print(\"**********************************************************************\")\n",
        "        print(\"\\nSELECCIONE EL PAÍS (SIT_SITE_ID):\")\n",
        "        site_options = ['MCO', 'MLC', 'MLA', 'MPE', 'MLU', 'MLM', 'MLB', 'MEC']\n",
        "        site_options.sort() # Sort the list alphabetically\n",
        "        for idx, option in enumerate(site_options):\n",
        "            print(f\"{idx + 1}. {option}\")\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                country_index = int(input(\"Ingrese el número del país: \")) - 1\n",
        "                if 0 <= country_index < len(site_options):\n",
        "                    country = site_options[country_index]\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"Número de país inválido. Inténtalo de nuevo.\")\n",
        "            except ValueError:\n",
        "                print(\"Entrada inválida. Por favor, ingrese un número.\")\n",
        "\n",
        "\n",
        "        print(\"\\nSELECCIONE EL TIPO DE INFORMACIÓN:\")\n",
        "        info_types = ['First Visit', 'Handling', 'Created']\n",
        "        for idx, option in enumerate(info_types):\n",
        "            print(f\"{idx + 1}. {option}\")\n",
        "\n",
        "        while True:\n",
        "            try:\n",
        "                info_type_index = int(input(\"Ingrese el número del tipo de información: \")) - 1\n",
        "                if 0 <= info_type_index < len(info_types):\n",
        "                    info_type = info_types[info_type_index]\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"Número de tipo de información inválido. Inténtalo de nuevo.\")\n",
        "            except ValueError:\n",
        "                print(\"Entrada inválida. Por favor, ingrese un número.\")\n",
        "\n",
        "        # Año\n",
        "        while True:\n",
        "            try:\n",
        "                year = int(input(f\"\\nINGRESE EL AÑO (2023 - {datetime.now().year}): \"))\n",
        "                if 2023 <= year <= datetime.now().year:\n",
        "                    break\n",
        "                else:\n",
        "                    print(\"Fecha inválida, debe ser entre 2023 y el año actual. Inténtalo de nuevo.\")\n",
        "            except ValueError:\n",
        "                print(\"Entrada inválida. Por favor, ingrese un número.\")\n",
        "\n",
        "\n",
        "        # Mes\n",
        "        while True:\n",
        "            try:\n",
        "                month = int(input(f\"\\nINGRESE EL MES (1 - 12): \"))\n",
        "                if 1 <= month <= 12:\n",
        "                    if year == datetime.now().year and month > datetime.now().month:\n",
        "                         print(\"Mes inválido para el año actual. Inténtalo de nuevo.\")\n",
        "                    else:\n",
        "                        break\n",
        "                else:\n",
        "                    print(\"Mes inválido, debe ser entre 1 y 12. Inténtalo de nuevo.\")\n",
        "            except ValueError:\n",
        "                print(\"Entrada inválida. Por favor, ingrese un número.\")\n",
        "\n",
        "\n",
        "        return country, info_type, year, month\n",
        "\n",
        "# Función para generar y ejecutar la consulta\n",
        "def execute_query(country, info_type, year, month):\n",
        "    month_str = f\"{month:02}\"\n",
        "\n",
        "    date_column_map = {\n",
        "        'First Visit': 'SHP_DATE_FIRST_VISIT_ID_LTZ',\n",
        "        'Handling': 'SHP_DATE_HANDLING_ID_LTZ',\n",
        "        'Created': 'SHP_DATE_CREATED_ID'\n",
        "    }\n",
        "\n",
        "    date_column = date_column_map[info_type]\n",
        "\n",
        "    print(f\"Executing query with:\")\n",
        "    print(f\"  Country: {country}\")\n",
        "    print(f\"  Info Type: {info_type}\")\n",
        "    print(f\"  Date Column: {date_column}\")\n",
        "    print(f\"  Year: {year}\")\n",
        "    print(f\"  Month: {month}\")\n",
        "\n",
        "\n",
        "    query = f\"\"\"\n",
        "    SELECT\n",
        "        SIT_SITE_ID,\n",
        "        COUNT(SHP_SHIPMENT_ID) AS SHP,\n",
        "        SUM (SHP_QUANTITY) AS SIS,\n",
        "        CASE\n",
        "            WHEN SIT_SITE_ID = 'MCO' AND SHP_ADD_STATE_ID_BUYER = 'CO-DC' THEN 'CO-BDC'\n",
        "            ELSE SHP_ADD_STATE_ID_BUYER\n",
        "        END AS SHP_ADD_STATE_ID_BUYER,\n",
        "        CASE\n",
        "            WHEN SIT_SITE_ID = 'MCO' AND SHP_ADD_STATE_ID_SELLER = 'CO-DC' THEN 'CO-BDC'\n",
        "            ELSE SHP_ADD_STATE_ID_SELLER\n",
        "        END AS SHP_ADD_STATE_ID_SELLER,\n",
        "        EXTRACT(YEAR FROM {date_column}) AS YEAR,\n",
        "        EXTRACT(MONTH FROM {date_column}) AS MONTH,\n",
        "        CASE\n",
        "            WHEN SHP_PICKING_TYPE_ID = 'drop_off' THEN 'DS'\n",
        "            WHEN SHP_PICKING_TYPE_ID = 'xd_drop_off' THEN 'XD'\n",
        "            WHEN SHP_PICKING_TYPE_ID = 'fulfillment' THEN 'FUL'\n",
        "            WHEN SHP_PICKING_TYPE_ID = 'cross_docking' THEN 'XD'\n",
        "            WHEN SHP_PICKING_TYPE_ID = 'self_service' THEN 'FLEX'\n",
        "            ELSE NULL\n",
        "        END AS SHP_PICKING_TYPE_ID,\n",
        "        CASE\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 0 THEN 'SD'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 1 THEN 'ND'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 2 THEN '2D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 3 THEN '3D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 4 THEN '4D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 5 THEN '5D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 6 THEN '6D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 7 THEN '7D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 8 THEN '8D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS = 9 THEN '9D'\n",
        "            WHEN SHP_LEAD_TIME_NATURAL_DAYS > 9 THEN '9DP'\n",
        "            ELSE NULL\n",
        "        END AS SHP_LEAD_TIME_NATURAL_DAYS\n",
        "    FROM `meli-bi-data.WHOWNER.LK_SHP_SHIPMENTS_HISTORICAL_ND`\n",
        "    WHERE\n",
        "        SIT_SITE_ID = '{country}' AND\n",
        "        LOWER(SHP_FLOW_TYPE) = 'forward' AND\n",
        "        SHP_SOURCE_ID = 'MELI' AND\n",
        "        EXTRACT(YEAR FROM {date_column}) = {year} AND\n",
        "        EXTRACT(MONTH FROM {date_column}) = {month} AND\n",
        "        SHP_LEAD_TIME_NATURAL_DAYS IS NOT NULL\n",
        "    GROUP BY\n",
        "        SIT_SITE_ID,\n",
        "        SHP_ADD_STATE_ID_BUYER,\n",
        "        SHP_ADD_STATE_ID_SELLER,\n",
        "        YEAR,\n",
        "        MONTH,\n",
        "        SHP_PICKING_TYPE_ID,\n",
        "        SHP_LEAD_TIME_NATURAL_DAYS\n",
        "    \"\"\"\n",
        "\n",
        "    df = client.query(query).result().to_dataframe()\n",
        "\n",
        "    print(f\"Number of rows returned by the query: {len(df)}\")\n",
        "    print(f\"Data type of 'SIS' column: {df['SIS'].dtype}\")\n",
        "    # print(\"\\nDataFrame columns after fetching from BigQuery:\")\n",
        "    # print(df.columns)\n",
        "    # Remove the display of the first 5 rows after fetching from BigQuery\n",
        "    # display(df.head())\n",
        "\n",
        "\n",
        "    # Rename Year and Month columns based on info_type\n",
        "    rename_map = {}\n",
        "    if info_type == 'First Visit':\n",
        "        rename_map['YEAR'] = 'YEAR_FV'\n",
        "        rename_map['MONTH'] = 'MONTH_FV'\n",
        "        year_col = 'YEAR_FV'\n",
        "        month_col = 'MONTH_FV'\n",
        "    elif info_type == 'Handling':\n",
        "        rename_map['YEAR'] = 'YEAR_HT'\n",
        "        rename_map['MONTH'] = 'MONTH_HT'\n",
        "        year_col = 'YEAR_HT'\n",
        "        month_col = 'MONTH_HT'\n",
        "    elif info_type == 'Created':\n",
        "        rename_map['YEAR'] = 'YEAR_C'\n",
        "        rename_map['MONTH'] = 'MONTH_C'\n",
        "        year_col = 'YEAR_C'\n",
        "        month_col = 'MONTH_C'\n",
        "\n",
        "\n",
        "    df.rename(columns=rename_map, inplace=True)\n",
        "\n",
        "    # Explicitly convert 'SIS' to numeric, coercing errors will turn unparseable values into NaN\n",
        "    df['SIS'] = pd.to_numeric(df['SIS'], errors='coerce')\n",
        "\n",
        "\n",
        "    df = df[df['SHP_PICKING_TYPE_ID'].notnull()]  # Ignorar no estándar\n",
        "\n",
        "    # Print unique values in SHP_LEAD_TIME_NATURAL_DAYS before standardization to debug\n",
        "    # print(\"Unique values in SHP_LEAD_TIME_NATURAL_DAYS before standardization:\")\n",
        "    # The SHP_LEAD_TIME_NATURAL_DAYS column is now the result of the CASE statement\n",
        "    # print(df['SHP_LEAD_TIME_NATURAL_DAYS'].unique())\n",
        "\n",
        "\n",
        "    # Calculate column SHARE_PT (J) based on the provided formula\n",
        "    # SUMIFS($H:$H;$A:$A;$A2;$B:$B;$B2;$C:$C;$C2;$D:$D;$D2;$E:$E;$E2;$F:$F;$F2;$G:$G;$G2)/SUMIFS($H:$H;$A:$A;$A2;$B:$B;$B2;$C:$C;$C2)\n",
        "    # H -> SHP, A -> SIT_SITE_ID, B -> YEAR_FV/HT/C, C -> MONTH_FV/HT/C, D -> SHP_PICKING_TYPE_ID, E -> SHP_ADD_STATE_ID_BUYER, F -> SHP_ADD_STATE_ID_SELLER, G -> SHP_LEAD_TIME_NATURAL_DAYS\n",
        "\n",
        "    # Calculate the denominator first (sum of SHP for each SIT_SITE_ID, Year, Month group)\n",
        "    denominator = df.groupby(['SIT_SITE_ID', year_col, month_col])['SHP'].transform('sum')\n",
        "\n",
        "    # Calculate the numerator (sum of SHP for each group defined by all relevant columns)\n",
        "    numerator = df.groupby(['SIT_SITE_ID', year_col, month_col, 'SHP_PICKING_TYPE_ID', 'SHP_ADD_STATE_ID_BUYER', 'SHP_ADD_STATE_ID_SELLER', 'SHP_LEAD_TIME_NATURAL_DAYS'])['SHP'].transform('sum')\n",
        "\n",
        "    # Calculate SHARE_PT, handling division by zero\n",
        "    df['SHARE_PT'] = numerator / denominator\n",
        "    df['SHARE_PT'] = df['SHARE_PT'].fillna(0) # Replace NaN resulting from division by zero with 0\n",
        "\n",
        "\n",
        "    # Calculate column SPEED_PT (K) based on the provided formula\n",
        "    # H2/SUMIFS($H:$H;$A:$A;$A2;$B:$B;$B2;$C:$C;$C2;$D:$D;D2)\n",
        "    # H -> SHP, A -> SIT_SITE_ID, B -> YEAR_FV/HT/C, C -> MONTH_FV/HT/C, D -> SHP_PICKING_TYPE_ID\n",
        "    speed_pt_denominator = df.groupby(['SIT_SITE_ID', year_col, month_col, 'SHP_PICKING_TYPE_ID'])['SHP'].transform('sum')\n",
        "    df['SPEED_PT'] = df['SHP'] / speed_pt_denominator\n",
        "    df['SPEED_PT'] = df['SPEED_PT'].fillna(0) # Replace NaN resulting from division by zero with 0\n",
        "\n",
        "\n",
        "    # Calculate column SPEED_ALL_NET (L) based on the provided formula\n",
        "    # K2*SUMIFS($J:$J;$A:$A;$A2;$B:$B;$B2;$C:$C;$C2;$D:$D;$D2)\n",
        "    # J -> SHARE_PT, A -> SIT_SITE_ID, B -> YEAR_FV/HT/C, C -> MONTH_FV/HT/C, D -> SHP_PICKING_TYPE_ID\n",
        "    speed_all_net_sumifs = df.groupby(['SIT_SITE_ID', year_col, month_col, 'SHP_PICKING_TYPE_ID'])['SHARE_PT'].transform('sum')\n",
        "    df['SPEED_ALL_NET'] = df['SPEED_PT'] * speed_all_net_sumifs\n",
        "\n",
        "\n",
        "    # print(\"\\nDataFrame columns after calculating new columns:\")\n",
        "    # print(df.columns)\n",
        "    # Remove the display of the first 5 rows after calculating new columns\n",
        "    # display(df.head())\n",
        "\n",
        "\n",
        "    # Reorder columns\n",
        "    if info_type == 'First Visit':\n",
        "        ordered_columns = ['SIT_SITE_ID', 'YEAR_FV', 'MONTH_FV', 'SHP_PICKING_TYPE_ID', 'SHP_ADD_STATE_ID_BUYER', 'SHP_ADD_STATE_ID_SELLER', 'SHP_LEAD_TIME_NATURAL_DAYS', 'SHP', 'SIS', 'SHARE_PT', 'SPEED_PT', 'SPEED_ALL_NET']\n",
        "    elif info_type == 'Handling':\n",
        "         ordered_columns = ['SIT_SITE_ID', 'YEAR_HT', 'MONTH_HT', 'SHP_PICKING_TYPE_ID', 'SHP_ADD_STATE_ID_BUYER', 'SHP_ADD_STATE_ID_SELLER', 'SHP_LEAD_TIME_NATURAL_DAYS', 'SHP', 'SIS', 'SHARE_PT', 'SPEED_PT', 'SPEED_ALL_NET']\n",
        "    elif info_type == 'Created':\n",
        "        ordered_columns = ['SIT_SITE_ID', 'YEAR_C', 'MONTH_C', 'SHP_PICKING_TYPE_ID', 'SHP_ADD_STATE_ID_BUYER', 'SHP_ADD_STATE_ID_SELLER', 'SHP_LEAD_TIME_NATURAL_DAYS', 'SHP', 'SIS', 'SHARE_PT', 'SPEED_PT', 'SPEED_ALL_NET']\n",
        "\n",
        "    # Ensure all required columns exist in the DataFrame before reordering\n",
        "    missing_columns = [col for col in ordered_columns if col not in df.columns]\n",
        "    if missing_columns:\n",
        "        print(f\"Warning: The following columns are missing from the DataFrame and cannot be reordered: {missing_columns}\")\n",
        "        # Proceed with reordering only the existing columns\n",
        "        ordered_columns = [col for col in ordered_columns if col in df.columns]\n",
        "\n",
        "\n",
        "    df = df[ordered_columns]\n",
        "\n",
        "    # print(\"\\nDataFrame columns after reordering:\")\n",
        "    # print(df.columns)\n",
        "    # Remove the display of the first 5 rows after reordering as requested by the user\n",
        "    # display(df.head())\n",
        "\n",
        "\n",
        "    # Guardar resultados a un archivo Excel\n",
        "    df.to_excel(\"info.xlsx\", index=False, sheet_name=\"Info Real\")\n",
        "    # print(\"Resultados guardados en 'info.xlsx' con la hoja 'Info Real'.\")\n",
        "\n",
        "# Ejecutar el menú y la consulta\n",
        "country, info_type, year, month = menu_selection()\n",
        "execute_query(country, info_type, year, month)"
      ],
      "metadata": {
        "id": "T6hElmEko7FI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b24c6d8-1031-4116-d9f0-1f08d69bad0c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "**********************************************************************\n",
            "POR FAVOR, PROPORCIONE LOS SIGUIENTES PARÁMETROS PARA OBTENER LA INFORMACIÓN HISTORICA/REAL:\n",
            "**********************************************************************\n",
            "\n",
            "SELECCIONE EL PAÍS (SIT_SITE_ID):\n",
            "1. MCO\n",
            "2. MEC\n",
            "3. MLA\n",
            "4. MLB\n",
            "5. MLC\n",
            "6. MLM\n",
            "7. MLU\n",
            "8. MPE\n",
            "Ingrese el número del país: 1\n",
            "\n",
            "SELECCIONE EL TIPO DE INFORMACIÓN:\n",
            "1. First Visit\n",
            "2. Handling\n",
            "3. Created\n",
            "Ingrese el número del tipo de información: 1\n",
            "\n",
            "INGRESE EL AÑO (2023 - 2025): 1\n",
            "Fecha inválida, debe ser entre 2023 y el año actual. Inténtalo de nuevo.\n",
            "\n",
            "INGRESE EL AÑO (2023 - 2025): 2025\n",
            "\n",
            "INGRESE EL MES (1 - 12): 1\n",
            "Executing query with:\n",
            "  Country: MCO\n",
            "  Info Type: First Visit\n",
            "  Date Column: SHP_DATE_FIRST_VISIT_ID_LTZ\n",
            "  Year: 2025\n",
            "  Month: 1\n",
            "Number of rows returned by the query: 10568\n",
            "Data type of 'SIS' column: object\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}